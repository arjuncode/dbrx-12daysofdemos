{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9965763d",
   "metadata": {},
   "source": [
    "**12 Days of Demos**\n",
    "# üéÖ North Pole Agent Tools (MCP) üéÑ\n",
    "\n",
    "Santa's operation is becoming increasingly complex. To help the elves (and Santa) make data-driven decisions, we are building a suite of **AI Agents**. But these agents need access to real-time data about the workshop, reindeer, and gift requests.\n",
    "\n",
    "This notebook demonstrates how to use the **Model Context Protocol (MCP)** to give agents access to Unity Catalog SQL Functions. Instead of just chatting, our agents can now **query the data** to answer questions like:\n",
    "\n",
    "* **Workshop Status**: How much glitter do we have left? Which elf team is performing best?\n",
    "* **Reindeer Telemetry**: Is Rudolph tired? What is the average flight altitude?\n",
    "* **Logistics**: Which delivery routes are impacted by weather?\n",
    "* **Gift Trends**: What are the most popular toys this year?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa05456",
   "metadata": {},
   "source": [
    "### ü¶å Step 1: Configuration\n",
    "\n",
    "Before you begin: Update the configuration below to match your environment.\n",
    "\n",
    "The default values point to the demo dataset, but you can customize:\n",
    "* **Catalog name** - Your Unity Catalog catalog\n",
    "* **Schema name** - Schema where your raw data are stored\n",
    "* **Volume Name** - Place where files should be stored prior to loading\n",
    "\n",
    "üëá **Update the cell below with your values, then run it!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6cfc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_CATALOG = \"12daysofdemos\"\n",
    "TARGET_SCHEMA = \"raw_data\"\n",
    "TARGET_VOLUME = \"raw_data_volume\"\n",
    "\n",
    "# Set variables for the functions below\n",
    "catalog_name = TARGET_CATALOG\n",
    "schema_name = TARGET_SCHEMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd501f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run \"../00-init/load-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42350b74",
   "metadata": {},
   "source": [
    "### üõ†Ô∏è Step 2: Define Agent Tools (SQL Functions)\n",
    "\n",
    "To give our AI agents the ability to \"see\" into our operations, we need to define **tools**. In the Model Context Protocol (MCP), tools are often implemented as functions that the agent can call.\n",
    "\n",
    "We will create a suite of **Unity Catalog SQL Functions** that encapsulate our business logic. These functions act as the API for our agents, allowing them to:\n",
    "*   **Check inventory levels** üè≠\n",
    "*   **Monitor reindeer health** ü¶å\n",
    "*   **Analyze gift requests** üéÅ\n",
    "*   **Optimize delivery routes** üöö\n",
    "\n",
    "*By defining these as SQL functions, we ensure that our agents always use approved, secure, and consistent logic!*\n",
    "\n",
    "üëá **Run the cells below to register these functions in Unity Catalog!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9922dd29",
   "metadata": {},
   "source": [
    "### üè≠ Workshop Production Metrics\n",
    "*Tracking material usage to ensure we don't run out of glitter!* ‚ú®"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ad5172",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_workshop_material_totals')()\n",
    "RETURNS TABLE(total_plastic_kg DOUBLE, total_wood_kg DOUBLE, total_metal_kg DOUBLE, total_fabric_kg DOUBLE)\n",
    "COMMENT 'Returns total usage of all materials in the workshop.'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    SUM(materials_plastic_kg) as total_plastic_kg,\n",
    "    SUM(materials_wood_kg) as total_wood_kg,\n",
    "    SUM(materials_metal_kg) as total_metal_kg,\n",
    "    SUM(materials_fabric_kg) as total_fabric_kg\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.workshop_production')\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5986635d",
   "metadata": {},
   "source": [
    "### üßù Elf Team Performance\n",
    "*Monitoring quality scores to find out which team deserves extra hot cocoa.* ‚òï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f241bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_team_quality_metrics')(team_ids STRING)\n",
    "RETURNS TABLE(team_id STRING, avg_paint_quality DOUBLE, avg_assembly_score DOUBLE, total_defects BIGINT)\n",
    "COMMENT 'Returns quality metrics for specific elf teams. Input: JSON Array. Example: \"[\"Team_B\", \"Team_C\"]\"'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    elf_team_id as team_id,\n",
    "    AVG(paint_quality) as avg_paint_quality,\n",
    "    AVG(assembly_score) as avg_assembly_score,\n",
    "    SUM(defect_count) as total_defects\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.workshop_production')\n",
    "  WHERE array_contains(from_json(team_ids, 'ARRAY<STRING>'), elf_team_id)\n",
    "  GROUP BY elf_team_id\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdb106d",
   "metadata": {},
   "source": [
    "### üìç Workshop Location Stats\n",
    "*Comparing efficiency across our North, South, East, and West workshops.* üß≠"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d757db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_workshop_location_metrics')(locations STRING)\n",
    "RETURNS TABLE(workshop_location STRING, avg_production_time DOUBLE, avg_carbon_footprint DOUBLE)\n",
    "COMMENT 'Returns performance metrics for specific workshop locations. Input: JSON Array. Example: \"[\"North_Workshop\", \"South_Workshop\"]\"'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    workshop_location,\n",
    "    AVG(production_time_minutes) as avg_production_time,\n",
    "    AVG(carbon_footprint_kg) as avg_carbon_footprint\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.workshop_production')\n",
    "  WHERE array_contains(from_json(locations, 'ARRAY<STRING>'), workshop_location)\n",
    "  GROUP BY workshop_location\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022a9d5f",
   "metadata": {},
   "source": [
    "### üß∏ Toy Defect Rates\n",
    "*Ensuring every toy brings joy, not disappointment.* üîß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9a96c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_toy_defect_rate')(categories STRING)\n",
    "RETURNS TABLE(toy_category STRING, defect_rate DOUBLE, total_produced BIGINT)\n",
    "COMMENT 'Returns the percentage of toys with defects for given categories. Input: JSON Array. Example: \"[\"VEHICLES\", \"TOYS\"]\"'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    toy_category,\n",
    "    CAST(SUM(CASE WHEN defect_count > 0 THEN 1 ELSE 0 END) AS DOUBLE) / COUNT(*) as defect_rate,\n",
    "    COUNT(*) as total_produced\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.workshop_production')\n",
    "  WHERE array_contains(from_json(categories, 'ARRAY<STRING>'), toy_category)\n",
    "  GROUP BY toy_category\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2ef048",
   "metadata": {},
   "source": [
    "### ‚è∞ Shift Performance\n",
    "*Analyzing productivity during the Morning, Afternoon, and Night shifts.* üåô"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2743781",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_shift_performance')(shifts STRING)\n",
    "RETURNS TABLE(shift STRING, avg_quality_tier STRING, avg_production_time DOUBLE)\n",
    "COMMENT 'Returns average production time and most common quality tier for specific shifts. Input: JSON Array. Example: \"[\"MORNING\", \"NIGHT\"]\"'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    shift,\n",
    "    mode(quality_tier) as avg_quality_tier,\n",
    "    AVG(production_time_minutes) as avg_production_time\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.workshop_production')\n",
    "  WHERE array_contains(from_json(shifts, 'ARRAY<STRING>'), shift)\n",
    "  GROUP BY shift\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76422d86",
   "metadata": {},
   "source": [
    "### üì¨ Delivery Preferences\n",
    "*Chimney, door, or window? Knowing how to deliver is half the battle!* üè†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14163bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_gift_requests_by_delivery_pref')(preferences STRING)\n",
    "RETURNS TABLE(delivery_preference STRING, request_count BIGINT, avg_urgency DOUBLE)\n",
    "COMMENT 'Returns count of requests and average urgency for delivery preferences. Input: JSON Array. Example: \"[\"chimney\", \"door\"]\"'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    delivery_preference,\n",
    "    COUNT(*) as request_count,\n",
    "    AVG(urgency_level) as avg_urgency\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.gift_requests')\n",
    "  WHERE array_contains(from_json(preferences, 'ARRAY<STRING>'), delivery_preference)\n",
    "  GROUP BY delivery_preference\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef2f792",
   "metadata": {},
   "source": [
    "### üéÅ Popular Gifts\n",
    "*What's trending this year? (Besides peace on earth).* üìà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_popular_gifts_by_category')(categories STRING)\n",
    "RETURNS TABLE(item_name STRING, request_count BIGINT)\n",
    "COMMENT 'Returns the top 5 most requested gifts in specific categories. Input: JSON Array. Example: \"[\"TOYS\", \"SPORTS\"]\"'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    gift_item.item_name,\n",
    "    COUNT(*) as request_count\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.gift_requests')\n",
    "  LATERAL VIEW explode(from_json(extracted_gifts_json, 'ARRAY<STRUCT<item_name: STRING, category: STRING, confidence_score: DOUBLE>>')) AS gift_item\n",
    "  WHERE array_contains(from_json(categories, 'ARRAY<STRING>'), primary_gift_category)\n",
    "  GROUP BY 1\n",
    "  ORDER BY 2 DESC\n",
    "  LIMIT 5\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c492d2",
   "metadata": {},
   "source": [
    "### üö® High Urgency Requests\n",
    "*Prioritizing the most critical wishes.* üÜò"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b589b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_high_urgency_requests')(min_urgency INT)\n",
    "RETURNS TABLE(request_id STRING, child_id STRING, urgency_level INT, country STRING)\n",
    "COMMENT 'Returns a list of gift requests with urgency level greater than or equal to the specified value. Example: 5'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    request_id,\n",
    "    child_id,\n",
    "    urgency_level,\n",
    "    country\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.gift_requests')\n",
    "  WHERE urgency_level >= min_urgency\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3801b9c6",
   "metadata": {},
   "source": [
    "### üåç Requests by Country\n",
    "*Mapping out global joy distribution.* üó∫Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbeb2def",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_gift_requests_by_country')(countries STRING)\n",
    "RETURNS TABLE(country STRING, total_requests BIGINT, avg_sentiment DOUBLE)\n",
    "COMMENT 'Returns total requests and average sentiment score for specific countries. Input: JSON Array. Example: \"[\"China\", \"USA\"]\"'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    country,\n",
    "    COUNT(*) as total_requests,\n",
    "    AVG(sentiment_score) as avg_sentiment\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.gift_requests')\n",
    "  WHERE array_contains(from_json(countries, 'ARRAY<STRING>'), country)\n",
    "  GROUP BY country\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7168dd37",
   "metadata": {},
   "source": [
    "### ü¶å Reindeer Flight Metrics\n",
    "*Checking speed and altitude stats for our antlered aviators.* ‚úàÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea51c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_reindeer_flight_metrics')(reindeer_names STRING)\n",
    "RETURNS TABLE(reindeer_name STRING, avg_speed_mph DOUBLE, avg_altitude_feet DOUBLE, max_heart_rate INT)\n",
    "COMMENT 'Returns average flight metrics for specific reindeer. Input: JSON Array. Example: \"[\"Rudolph\", \"Dasher\"]\"'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    reindeer_name,\n",
    "    AVG(speed_mph) as avg_speed_mph,\n",
    "    AVG(altitude_feet) as avg_altitude_feet,\n",
    "    MAX(heart_rate) as max_heart_rate\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.reindeer_telemetry')\n",
    "  WHERE array_contains(from_json(reindeer_names, 'ARRAY<STRING>'), reindeer_name) AND flight_status = 'FLYING'\n",
    "  GROUP BY reindeer_name\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ace40b0",
   "metadata": {},
   "source": [
    "### üõ∏ Live Flight Status\n",
    "*Who is currently in the air?* üì°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71f689c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_flying_reindeer_status')()\n",
    "RETURNS TABLE(reindeer_name STRING, current_speed DOUBLE, current_altitude DOUBLE)\n",
    "COMMENT 'Returns a list of reindeer currently in flight status.'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    reindeer_name,\n",
    "    speed_mph as current_speed,\n",
    "    altitude_feet as current_altitude\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.reindeer_telemetry')\n",
    "  WHERE flight_status = 'FLYING'\n",
    "  ORDER BY timestamp DESC\n",
    "  LIMIT 9\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cb7ca5",
   "metadata": {},
   "source": [
    "### ü•ï Low Energy Reindeer\n",
    "*Identifying who needs a carrot break.* ü•ï"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4153121",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_low_energy_reindeer')(threshold DOUBLE)\n",
    "RETURNS TABLE(reindeer_name STRING, energy_efficiency DOUBLE, timestamp TIMESTAMP)\n",
    "COMMENT 'Returns reindeer with energy efficiency below a certain threshold. Example: 0.85'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    reindeer_name,\n",
    "    energy_efficiency,\n",
    "    timestamp\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.reindeer_telemetry')\n",
    "  WHERE energy_efficiency < threshold\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030eecd9",
   "metadata": {},
   "source": [
    "### üêæ Hoof Pressure Analysis\n",
    "*Ensuring soft landings on every roof.* üè†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65858b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_average_hoof_pressure')()\n",
    "RETURNS TABLE(avg_pressure_fl DOUBLE, avg_pressure_fr DOUBLE, avg_pressure_rl DOUBLE, avg_pressure_rr DOUBLE)\n",
    "COMMENT 'Returns average hoof pressure for all reindeer across all four limbs.'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    AVG(hoof_pressure_fl) as avg_pressure_fl,\n",
    "    AVG(hoof_pressure_fr) as avg_pressure_fr,\n",
    "    AVG(hoof_pressure_rl) as avg_pressure_rl,\n",
    "    AVG(hoof_pressure_rr) as avg_pressure_rr\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.reindeer_telemetry')\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7790a04f",
   "metadata": {},
   "source": [
    "### üöö Route Metrics\n",
    "*Optimizing the path from A to B (or North Pole to Everywhere).* üõ£Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d866e0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_delivery_route_metrics')(start_city STRING, end_city STRING)\n",
    "RETURNS TABLE(start_city STRING, end_city STRING, avg_distance_km DOUBLE, avg_delivery_window DOUBLE)\n",
    "COMMENT 'Returns average distance and delivery window for a specific route segment. Example: \"Tokyo\", \"London\"'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    start_city,\n",
    "    end_city,\n",
    "    AVG(distance_km) as avg_distance_km,\n",
    "    AVG(delivery_window_minutes) as avg_delivery_window\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.delivery_optimization')\n",
    "  WHERE start_city = start_city AND end_city = end_city\n",
    "  GROUP BY start_city, end_city\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206c2382",
   "metadata": {},
   "source": [
    "### ‚ùÑÔ∏è Weather Impact\n",
    "*How much does a blizzard slow us down?* üå®Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d56e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_weather_impact_on_delivery')(weather_conditions STRING)\n",
    "RETURNS TABLE(weather_condition STRING, avg_delay_minutes DOUBLE, count_routes BIGINT)\n",
    "COMMENT 'Returns average delay minutes caused by specific weather conditions. Input: JSON Array. Example: \"[\"HEAVY_SNOW\", \"FOG\"]\"'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    weather_condition,\n",
    "    AVG(weather_delay_minutes) as avg_delay_minutes,\n",
    "    COUNT(*) as count_routes\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.delivery_optimization')\n",
    "  WHERE array_contains(from_json(weather_conditions, 'ARRAY<STRING>'), weather_condition)\n",
    "  GROUP BY weather_condition\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3852ccf",
   "metadata": {},
   "source": [
    "### üß± Chimney Accessibility\n",
    "*Calculating the \"Santa-fit\" factor for each city.* üéÖ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b676049",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_chimney_accessibility')(city_names STRING)\n",
    "RETURNS TABLE(city_name STRING, total_households BIGINT, chimneys_available BIGINT, accessibility_rate DOUBLE)\n",
    "COMMENT 'Returns chimney availability statistics for given cities. Input: JSON Array. Example: \"[\"London\", \"Paris\"]\"'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    start_city as city_name,\n",
    "    SUM(households_count) as total_households,\n",
    "    SUM(chimneys_available) as chimneys_available,\n",
    "    SUM(chimneys_available) / SUM(households_count) as accessibility_rate\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.delivery_optimization')\n",
    "  WHERE array_contains(from_json(city_names, 'ARRAY<STRING>'), start_city)\n",
    "  GROUP BY start_city\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295f0e1e",
   "metadata": {},
   "source": [
    "### üìú Naughty or Nice Score\n",
    "*The most important metric of all.* ‚öñÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d45c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_child_naughty_nice_score')(child_ids STRING)\n",
    "RETURNS TABLE(child_id STRING, current_score DOUBLE, gift_tier STRING)\n",
    "COMMENT 'Returns the current running score and gift tier recommendation for specific children. Input: JSON Array. Example: \"[\"CH_IQ_30379\"]\"'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    child_id,\n",
    "    running_score as current_score,\n",
    "    gift_tier_recommendation as gift_tier\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.behavioral_analytics')\n",
    "  WHERE array_contains(from_json(child_ids, 'ARRAY<STRING>'), child_id)\n",
    "  ORDER BY timestamp DESC\n",
    "  LIMIT 1\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6b5048",
   "metadata": {},
   "source": [
    "### üé≠ Behavior Event Analysis\n",
    "*Tracking kindness, sharing, and... tantrums.* üìä"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854fdaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_behavior_events_by_type')(event_types STRING)\n",
    "RETURNS TABLE(event_type STRING, event_count BIGINT, avg_impact DOUBLE)\n",
    "COMMENT 'Returns statistics for specific types of behavioral events. Input: JSON Array. Example: \"[\"SHARING\", \"KINDNESS_ACT\"]\"'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    event_type,\n",
    "    COUNT(*) as event_count,\n",
    "    AVG(impact_score) as avg_impact\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.behavioral_analytics')\n",
    "  WHERE array_contains(from_json(event_types, 'ARRAY<STRING>'), event_type)\n",
    "  GROUP BY event_type\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200ce9a4",
   "metadata": {},
   "source": [
    "### üåü Top Nice Children\n",
    "*The gold standard of good behavior.* üèÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3722089",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_top_nice_children')()\n",
    "RETURNS TABLE(child_id STRING, running_score DOUBLE, country STRING)\n",
    "COMMENT 'Returns the top N children with the highest nice scores.'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    child_id,\n",
    "    MAX(running_score) as running_score,\n",
    "    first(location_country) as country\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.behavioral_analytics')\n",
    "  GROUP BY child_id\n",
    "  ORDER BY running_score DESC\n",
    "  LIMIT 25\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819c2241",
   "metadata": {},
   "source": [
    "### ‚ö´ Coal Warning List\n",
    "*It's not too late to turn it around!* ‚ö†Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538e2a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_coal_warning_list')()\n",
    "RETURNS TABLE(child_id STRING, running_score DOUBLE, warning_date TIMESTAMP)\n",
    "COMMENT 'Returns a list of children currently in the COAL_WARNING tier.'\n",
    "RETURN (\n",
    "  SELECT \n",
    "    child_id,\n",
    "    running_score,\n",
    "    timestamp as warning_date\n",
    "  FROM IDENTIFIER('{catalog_name}.{schema_name}.behavioral_analytics')\n",
    "  WHERE gift_tier_recommendation = 'COAL_WARNING'\n",
    "  ORDER BY timestamp DESC\n",
    ");\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf850337",
   "metadata": {},
   "source": [
    "### üîç Lookup Functions\n",
    "*Helper functions to help agents discover valid input values.* üîé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313e61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------------------------------------------\n",
    "# Lookup Functions (Grounding)\n",
    "# -------------------------------------------------------------------------\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_valid_elf_teams')()\n",
    "RETURNS TABLE(elf_team_id STRING)\n",
    "COMMENT 'Returns a list of all valid elf team IDs.'\n",
    "RETURN (SELECT DISTINCT elf_team_id FROM IDENTIFIER('{catalog_name}.{schema_name}.workshop_production') ORDER BY 1);\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_valid_workshop_locations')()\n",
    "RETURNS TABLE(workshop_location STRING)\n",
    "COMMENT 'Returns a list of all valid workshop locations.'\n",
    "RETURN (SELECT DISTINCT workshop_location FROM IDENTIFIER('{catalog_name}.{schema_name}.workshop_production') ORDER BY 1);\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_valid_toy_categories')()\n",
    "RETURNS TABLE(toy_category STRING)\n",
    "COMMENT 'Returns a list of all valid toy categories.'\n",
    "RETURN (SELECT DISTINCT toy_category FROM IDENTIFIER('{catalog_name}.{schema_name}.workshop_production') ORDER BY 1);\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_valid_shifts')()\n",
    "RETURNS TABLE(shift STRING)\n",
    "COMMENT 'Returns a list of all valid shifts.'\n",
    "RETURN (SELECT DISTINCT shift FROM IDENTIFIER('{catalog_name}.{schema_name}.workshop_production') ORDER BY 1);\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_valid_delivery_preferences')()\n",
    "RETURNS TABLE(delivery_preference STRING)\n",
    "COMMENT 'Returns a list of all valid delivery preferences.'\n",
    "RETURN (SELECT DISTINCT delivery_preference FROM IDENTIFIER('{catalog_name}.{schema_name}.gift_requests') ORDER BY 1);\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_valid_countries')()\n",
    "RETURNS TABLE(country STRING)\n",
    "COMMENT 'Returns a list of all valid countries.'\n",
    "RETURN (SELECT DISTINCT country FROM IDENTIFIER('{catalog_name}.{schema_name}.gift_requests') ORDER BY 1);\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_valid_reindeer_names')()\n",
    "RETURNS TABLE(reindeer_name STRING)\n",
    "COMMENT 'Returns a list of all valid reindeer names.'\n",
    "RETURN (SELECT DISTINCT reindeer_name FROM IDENTIFIER('{catalog_name}.{schema_name}.reindeer_telemetry') ORDER BY 1);\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_valid_weather_conditions')()\n",
    "RETURNS TABLE(weather_condition STRING)\n",
    "COMMENT 'Returns a list of all valid weather conditions.'\n",
    "RETURN (SELECT DISTINCT weather_condition FROM IDENTIFIER('{catalog_name}.{schema_name}.delivery_optimization') ORDER BY 1);\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION IDENTIFIER('{catalog_name}.{schema_name}.get_valid_behavior_event_types')()\n",
    "RETURNS TABLE(event_type STRING)\n",
    "COMMENT 'Returns a list of all valid behavior event types.'\n",
    "RETURN (SELECT DISTINCT event_type FROM IDENTIFIER('{catalog_name}.{schema_name}.behavioral_analytics') ORDER BY 1);\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
