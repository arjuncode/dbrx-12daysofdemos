{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ğŸ… Welcome to the North Pole Data Governance Office!\n## Unity Catalog Functions: Secure, Reusable Tools for Santa's Workshop\n\n---\n\n### ğŸ“¬ The Challenge\nSanta receives **millions of letters** from children worldwide, containing sensitive information:\n* ğŸ‘¶ **Names** - Personal identifiers that need protection\n* ğŸ  **Locations** - Cities and provinces where children live\n\n### âœ¨ The Solution: Unity Catalog Functions\nThe North Pole Modernization Office (NPMO) uses **Unity Catalog Functions** to create governed, reusable data tools that:\n* âœ… **Protect PII** - Automatic masking of sensitive data\n* âœ… **Enable Safe Queries** - Governed access patterns\n* âœ… **Track Lineage** - Unity Catalog monitors all usage\n* âœ… **Reusable Everywhere** - SQL, Python, dashboards, and applications\n\n### ğŸ¯ What You'll Learn\n* How to create **scalar functions** for data masking\n* How to build **aggregate functions** for governed queries\n* How to create **table-valued functions** for safe search\n\n---\n\n## ğŸ—ï¸ Architecture Overview\n\n```\nâ”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\nâ”‚ ğŸ“¬ Letters   â”‚     â”‚                    Data Intelligence Platform                           â”‚     â”‚ ğŸ›¡ï¸ Masked    â”‚\nâ”‚ ğŸ‘¶ Names     â”‚ â”€â”€â–º â”‚  [1.Scalar]â”€â”€â–º[2.Aggregate]â”€â”€â–º[3.Table-Valued]â”€â”€â–º[4.Governed Views]    â”‚ â”€â”€â–º â”‚ ğŸ“Š Analytics â”‚\nâ”‚ ğŸ  Locations â”‚     â”‚     mask_name()   get_province()   search_letters()   letters_masked   â”‚     â”‚ ğŸ” Search    â”‚\nâ””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n                     â”‚  [Delta Lake] [Apache Sparkâ„¢] [Unity Catalog] [Row/Column Security]    â”‚\n                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n```\n\nğŸ“ **Full architecture diagram:** [uc_functions_architecture.html](uc_functions_architecture.html)\n\n---\n\n*\"Security isn't just policy at the North Pole - it's built into the data platform!\"* ğŸ„âœ¨"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ Step 0: Configuration Setup\n",
    "\n",
    "### What's Happening Here?\n",
    "Before we build our governed functions, we need to set up our workspace.\n",
    "\n",
    "**We're configuring:**\n",
    "* ğŸ“š **Catalog & Schema**: Where our functions will live\n",
    "* ğŸ“‹ **Source Table**: Letters from Canadian children\n",
    "\n",
    "ğŸ¯ **Pro Tip**: Update the configuration below to match your environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ„ CONFIGURATION - Update these values for your environment!\nCATALOG = \"main\"\nSCHEMA = \"dbrx_12daysofdemos\"\nSOURCE_TABLE = \"santa_letters_canada_with_emails\"\n\n# Derived names (no need to change)\nfull_schema = f\"{CATALOG}.{SCHEMA}\"\nsource_table = f\"{full_schema}.{SOURCE_TABLE}\"\n\nprint(\"ğŸ… North Pole UC Functions Configuration\")\nprint(\"=\" * 60)\nprint(f\"ğŸ“š Catalog: {CATALOG}\")\nprint(f\"ğŸ“ Schema: {SCHEMA}\")\nprint(f\"ğŸ“‹ Source Table: {source_table}\")\nprint(\"=\" * 60)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the catalog and schema\n",
    "spark.sql(f\"USE CATALOG {CATALOG}\")\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {full_schema}\")\n",
    "spark.sql(f\"USE SCHEMA {SCHEMA}\")\n",
    "\n",
    "print(f\"âœ… Using catalog: {CATALOG}\")\n",
    "print(f\"âœ… Using schema: {full_schema}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Step 1: Explore the Raw Data (The Problem!)\n",
    "\n",
    "### What's Happening Here?\n",
    "Let's look at our raw letter data to understand **why we need governance**.\n",
    "\n",
    "âš ï¸ **The Problem**: This raw data is NOT safe to share with:\n",
    "* External dashboards\n",
    "* Demo environments\n",
    "* Third-party applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# âš ï¸ RAW DATA - Contains visible PII!\n",
    "print(\"âš ï¸ Raw data with visible PII - NOT safe to share!\\n\")\n",
    "\n",
    "df = spark.sql(f\"\"\"\n",
    "SELECT\n",
    "  name,\n",
    "  city,\n",
    "  province,\n",
    "  LEFT(letter, 150) AS letter_preview,\n",
    "  gifts\n",
    "FROM {source_table}\n",
    "LIMIT 10\n",
    "\"\"\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ”’ Part 1: Building PII Protection Functions\n",
    "\n",
    "---\n",
    "\n",
    "## What Are UC Scalar Functions?\n",
    "\n",
    "**Scalar functions** take input values and return a single output value. Perfect for:\n",
    "* Data masking (hiding sensitive parts)\n",
    "* Data transformation (formatting, cleaning)\n",
    "* Calculations (derived values)\n",
    "\n",
    "**The Magic:** Once created, these functions can be used everywhere - SQL, Python, dashboards! ğŸ…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‘¶ Function 1: `mask_name()` - Name Anonymization\n",
    "\n",
    "### Why This Matters\n",
    "Children's names require special protection:\n",
    "* ğŸ›¡ï¸ **Child Privacy Laws** - Extra protection for minors\n",
    "* ğŸ­ **Anonymization** - Enable analytics without identifying individuals\n",
    "\n",
    "### How It Works\n",
    "* **Input:** `Emma`\n",
    "* **Output:** `E**a`\n",
    "* Shows first and last character only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ­ Create the mask_name() function\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE FUNCTION mask_name(name STRING)\n",
    "RETURNS STRING\n",
    "COMMENT 'Masks personal names for privacy - shows first and last character only'\n",
    "RETURN\n",
    "  CASE\n",
    "    WHEN name IS NULL OR TRIM(name) = '' THEN NULL\n",
    "    WHEN LENGTH(TRIM(name)) <= 2 THEN REPEAT('*', LENGTH(TRIM(name)))\n",
    "    ELSE CONCAT(\n",
    "      SUBSTRING(TRIM(name), 1, 1),\n",
    "      REPEAT('*', LENGTH(TRIM(name)) - 2),\n",
    "      SUBSTRING(TRIM(name), -1)\n",
    "    )\n",
    "  END\n",
    "\"\"\")\n",
    "\n",
    "print(\"âœ… Created function: mask_name()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª Test mask_name()\n",
    "print(\"ğŸ§ª Testing mask_name() function:\\n\")\n",
    "\n",
    "df = spark.sql(\"\"\"\n",
    "SELECT\n",
    "  'Emma' AS original_name,\n",
    "  mask_name('Emma') AS masked_name\n",
    "UNION ALL\n",
    "SELECT\n",
    "  'Alexander' AS original_name,\n",
    "  mask_name('Alexander') AS masked_name\n",
    "UNION ALL\n",
    "SELECT\n",
    "  'Jo' AS original_name,\n",
    "  mask_name('Jo') AS masked_name\n",
    "\"\"\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Why UC Functions for Masking?\n",
    "\n",
    "| Traditional Approach | UC Functions |\n",
    "|---------------------|---------------|\n",
    "| Masking logic in application code | Masking built into the data layer |\n",
    "| Different implementations per system | Same function everywhere |\n",
    "| No audit trail | Full Unity Catalog lineage |\n",
    "| Easy to forget/bypass | Automatic when function is used |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ“Š Part 2: Aggregate Functions for Governed Queries\n",
    "\n",
    "---\n",
    "\n",
    "## Why Aggregate Functions?\n",
    "\n",
    "Users often need to answer questions like:\n",
    "* *\"How many letters from Ontario?\"*\n",
    "* *\"What's the most popular gift in Quebec?\"*\n",
    "\n",
    "**The Solution:** Create functions that return **governed, pre-aggregated data**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—ºï¸ Function 2: `get_province_summary()` - Governed Stats\n",
    "\n",
    "### How It Works\n",
    "* **Input:** Province name (e.g., 'Ontario')\n",
    "* **Output:** JSON with letter count, cities, sample gifts\n",
    "\n",
    "### Why JSON Output?\n",
    "* ğŸ“Š **Structured** - Consistent format every time\n",
    "* ğŸ”’ **Controlled** - Only returns approved fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Create the get_province_summary() function\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION get_province_summary(province_name STRING)\n",
    "RETURNS STRING\n",
    "COMMENT 'Returns JSON summary of letters from a specific province'\n",
    "RETURN (\n",
    "  SELECT TO_JSON(\n",
    "    STRUCT(\n",
    "      province_name AS province,\n",
    "      COUNT(*) AS total_letters,\n",
    "      COUNT(DISTINCT city) AS unique_cities,\n",
    "      SLICE(COLLECT_SET(SUBSTRING(gifts, 1, 50)), 1, 10) AS sample_gifts\n",
    "    )\n",
    "  )\n",
    "  FROM {source_table}\n",
    "  WHERE UPPER(province) = UPPER(province_name)\n",
    "     OR province = province_name\n",
    ")\n",
    "\"\"\")\n",
    "\n",
    "print(\"âœ… Created function: get_province_summary()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª Test get_province_summary()\n",
    "print(\"ğŸ§ª Testing get_province_summary() function:\\n\")\n",
    "\n",
    "df = spark.sql(\"SELECT get_province_summary('Ontario') AS ontario_stats\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ—ºï¸ Compare multiple provinces\n",
    "print(\"ğŸ—ºï¸ Province Comparison:\\n\")\n",
    "\n",
    "df = spark.sql(\"\"\"\n",
    "SELECT 'Ontario' AS province, get_province_summary('Ontario') AS stats\n",
    "UNION ALL\n",
    "SELECT 'Quebec' AS province, get_province_summary('Quebec') AS stats\n",
    "UNION ALL\n",
    "SELECT 'British Columbia' AS province, get_province_summary('British Columbia') AS stats\n",
    "\"\"\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ” Part 3: Table-Valued Functions for Safe Search\n",
    "\n",
    "---\n",
    "\n",
    "## What Are Table-Valued Functions?\n",
    "\n",
    "Unlike scalar functions (which return one value), **table-valued functions** return **entire result sets**.\n",
    "\n",
    "**Perfect for:**\n",
    "* Search functionality (find matching records)\n",
    "* Filtered views (subset of data)\n",
    "* Complex queries with automatic masking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Function 3: `search_letters()` - Safe Keyword Search\n",
    "\n",
    "### How It Works\n",
    "* **Input:** Keyword to search (e.g., 'bicycle')\n",
    "* **Output:** Results with AUTOMATICALLY MASKED names!\n",
    "\n",
    "### Built-In Safety\n",
    "* ğŸ­ Names are masked using our `mask_name()` function\n",
    "* ğŸ“ Letter previews have names replaced with masked versions\n",
    "* ğŸ”¢ Limited to 10 results per search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ” Create the search_letters() table-valued function\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE FUNCTION search_letters(keyword STRING)\n",
    "RETURNS TABLE(\n",
    "  masked_name STRING,\n",
    "  city STRING,\n",
    "  province STRING,\n",
    "  letter_preview STRING\n",
    ")\n",
    "COMMENT 'Searches letters by keyword and returns results with masked names'\n",
    "RETURN\n",
    "  SELECT\n",
    "    mask_name(name) AS masked_name,\n",
    "    city,\n",
    "    province,\n",
    "    SUBSTRING(REGEXP_REPLACE(letter, name, mask_name(name)), 1, 200) AS letter_preview\n",
    "  FROM {source_table}\n",
    "  WHERE UPPER(letter) LIKE CONCAT('%', UPPER(keyword), '%')\n",
    "     OR UPPER(gifts) LIKE CONCAT('%', UPPER(keyword), '%')\n",
    "  LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "print(\"âœ… Created function: search_letters()\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª Test search_letters() - Bicycles\n",
    "print(\"ğŸ” Searching for: 'bicycle'\\n\")\n",
    "\n",
    "df = spark.sql(\"SELECT * FROM search_letters('bicycle')\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª Test search_letters() - LEGO\n",
    "print(\"ğŸ” Searching for: 'LEGO'\\n\")\n",
    "\n",
    "df = spark.sql(\"SELECT * FROM search_letters('LEGO')\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# ğŸ§ª Test search_letters() - Nintendo\nprint(\"ğŸ” Searching for: 'Nintendo'\\n\")\n\ndf = spark.sql(\"SELECT * FROM search_letters('Nintendo')\")\ndisplay(df)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ’¡ Notice the Magic!\n",
    "\n",
    "**All results have automatically masked names!**\n",
    "\n",
    "* âœ… Never sees real child names\n",
    "* âœ… Gets useful, relevant results\n",
    "* âœ… All usage is tracked in Unity Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# ğŸ¯ Part 4: Putting It All Together\n",
    "\n",
    "---\n",
    "\n",
    "## Verify All Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“‹ List all functions we created\n",
    "print(\"ğŸ“‹ UC Functions in our schema:\\n\")\n",
    "\n",
    "df = spark.sql(\"SHOW USER FUNCTIONS\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”’ Create a Governed View\n",
    "\n",
    "Combine our masking functions into a **reusable view** that's always safe to query!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ”’ Create a masked view using our functions\n",
    "masked_view = f\"{full_schema}.holiday_letters_masked\"\n",
    "\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE VIEW {masked_view} AS\n",
    "SELECT\n",
    "  mask_name(name) AS child_name,\n",
    "  city,\n",
    "  province,\n",
    "  REGEXP_REPLACE(letter, name, mask_name(name)) AS letter,\n",
    "  gifts\n",
    "FROM {source_table}\n",
    "\"\"\")\n",
    "\n",
    "print(f\"âœ… Created governed view: {masked_view}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ‘€ Query the masked view\n",
    "print(\"ğŸ”’ Data from governed view (all PII masked):\\n\")\n",
    "\n",
    "df = spark.sql(f\"SELECT * FROM {masked_view} LIMIT 10\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“Š Analytics with Governed Data\n",
    "\n",
    "Run analytics on the masked view - safe to share anywhere!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“Š Letters by province (safe to share!)\n",
    "print(\"ğŸ“Š Letters by Province:\\n\")\n",
    "\n",
    "df = spark.sql(f\"\"\"\n",
    "SELECT\n",
    "  province,\n",
    "  COUNT(*) AS letter_count,\n",
    "  COUNT(DISTINCT city) AS unique_cities\n",
    "FROM {masked_view}\n",
    "GROUP BY province\n",
    "ORDER BY letter_count DESC\n",
    "\"\"\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ Top gift requests (anonymized)\n",
    "print(\"ğŸ Top Gift Requests (with anonymized requesters):\\n\")\n",
    "\n",
    "df = spark.sql(f\"\"\"\n",
    "SELECT\n",
    "  gifts,\n",
    "  COUNT(*) AS request_count,\n",
    "  SLICE(COLLECT_LIST(child_name), 1, 5) AS sample_requesters\n",
    "FROM {masked_view}\n",
    "WHERE gifts IS NOT NULL\n",
    "GROUP BY gifts\n",
    "ORDER BY request_count DESC\n",
    "LIMIT 15\n",
    "\"\"\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# ğŸŠ Congratulations! You've Built a Governed Data Platform!\n\n---\n\n## ğŸ“ What You Learned\n\n### âœ… Functions Created\n| Function | Type | Purpose |\n|----------|------|--------|\n| `mask_name()` | Scalar | Anonymize personal names |\n| `get_province_summary()` | Scalar (JSON) | Governed aggregate stats |\n| `search_letters()` | Table-valued | Safe search with auto-masking |\n\n---\n\n## ğŸ”‘ Key Takeaways\n\n| Traditional | UC Functions |\n|-------------|---------------|\n| Masking in app code | Masking built into data layer |\n| Different per system | Same function everywhere |\n| No lineage tracking | Full Unity Catalog lineage |\n| Easy to bypass | Enforced at query time |\n\n---\n\n## ğŸ… From the North Pole Team\n\n*\"Santa checks his list twice, but with Unity Catalog Functions, the data checks itself! Now that's what we call governance magic.\"*\n\n**- Mrs. Claus, Chief Data Officer**\n\n---\n\n### ğŸ„ Happy Holidays from Databricks! ğŸ„"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}