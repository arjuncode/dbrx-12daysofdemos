{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1e1bc71a-9aed-4ede-914b-3632ee7a8c95",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Initialize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3884b0fa-1957-45a1-af55-777c43211126",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../00-init/load-data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4e6aafc3-323e-471c-bd04-a890c1cf22c7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Delta Table Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "53b0a9cb-2cfd-4ed8-a184-0313e939bea3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def prepare_source_table_schema(table_name):\n",
    "    print(f\"Ensuring schema columns exist for {table_name}...\")\n",
    "    try:\n",
    "        current_schema = spark.table(table_name).columns\n",
    "        columns_to_add = []\n",
    "\n",
    "        if \"en_route\" not in current_schema:\n",
    "            spark.sql(f\"ALTER TABLE {table_name} ADD COLUMN en_route BOOLEAN\")\n",
    "            spark.sql(f\"UPDATE {table_name} SET en_route = False\")\n",
    "\n",
    "        if \"delivered\" not in current_schema:\n",
    "            spark.sql(f\"ALTER TABLE {table_name} ADD COLUMN delivered BOOLEAN\")\n",
    "            spark.sql(f\"UPDATE {table_name} SET delivered = False\")\n",
    "\n",
    "        if \"cookies\" not in current_schema:\n",
    "            spark.sql(f\"ALTER TABLE {table_name} ADD COLUMN cookies INT\")\n",
    "            spark.sql(f\"UPDATE {table_name} SET cookies = Null\")\n",
    "\n",
    "        print(\"✓ Schema meets requirements.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error modifying source table. Error: {e}\")\n",
    "        raise e\n",
    "\n",
    "source_table_name = \"main.dbrx_12daysofdemos.gift_requests\"\n",
    "prepare_source_table_schema(source_table_name)\n",
    "\n",
    "spark.sql(f\"ALTER TABLE {source_table_name} SET TBLPROPERTIES (delta.enableChangeDataFeed = true)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4634a312-92ca-487a-ba35-e333bd2106bc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Setup Lakebase using Databricks SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6aa16c65-a5e9-4acc-b426-22e6ee3b1a4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Example: Create a Lakebase instance using the Databricks SDK\n",
    "from databricks.sdk import WorkspaceClient\n",
    "from databricks.sdk.service.database import DatabaseInstance, DatabaseCatalog, SyncedDatabaseTable, SyncedTableSpec, NewPipelineSpec, SyncedTableSchedulingPolicy\n",
    "\n",
    "# Initialize the Databricks workspace client\n",
    "w = WorkspaceClient()\n",
    "\n",
    "# Configure the database instance class\n",
    "db_instance_config = DatabaseInstance(\n",
    "    name=\"lakebase-demo\",\n",
    "    capacity=\"CU_2\",  # Compute capacity: CU_1, CU_2, CU_4, etc.\n",
    "  )\n",
    "\n",
    "# Create a new Lakebase database instance\n",
    "instance = w.database.create_database_instance(db_instance_config)\n",
    "\n",
    "print(f\"✓ Instance created: {db_instance_config.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "922080e3-b3cf-44f9-8d85-2b7e06a31520",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configure the catalog class\n",
    "catalog_config = DatabaseCatalog(\n",
    "        name=\"lakebase_demo_catalog\",                    # Name of the UC catalog to create\n",
    "        database_instance_name=db_instance_config.name,         # Name of the database instance\n",
    "        database_name=\"databricks_postgres\",             # Name of the existing Postgres database\n",
    "    )\n",
    "\n",
    "# Register an existing database as a UC catalog\n",
    "catalog = w.database.create_database_catalog(catalog_config)\n",
    "print(f\"✓ Created database catalog: {catalog_config.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cf46770e-dfa6-404d-8e15-cf5224b68c1f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Create the Synced Lakebase Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26052cef-b57d-4e82-b391-668fcc820452",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Configure the synced table spec class\n",
    "synced_table_spec = SyncedTableSpec(\n",
    "            source_table_full_name=source_table_name,\n",
    "            primary_key_columns=[\"request_id\"],  # Primary key columns\n",
    "            scheduling_policy=SyncedTableSchedulingPolicy.TRIGGERED,\n",
    "            timeseries_key=\"timestamp\",  # For deduplication\n",
    "            new_pipeline_spec=NewPipelineSpec(\n",
    "                storage_catalog=\"main\",\n",
    "                storage_schema=\"dbrx_12daysofdemos\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "# Configure the synced table class\n",
    "synced_table_config = SyncedDatabaseTable(\n",
    "        name=catalog_config.name+\".public.gift_requests_synced_table\",\n",
    "        spec=synced_table_spec,\n",
    "    )\n",
    "\n",
    "# Create a synced table in a database catalog\n",
    "synced_table = w.database.create_synced_database_table(synced_table_config)\n",
    "print(f\"✓ Created synced table: {synced_table_config.name}\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "databricks-sdk>=0.73.0"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7929523548718616,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "lakebase-demo",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
